---
title: "Fitness Tracker Case Study"
author: "Deepa"
date: "2023-07-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

# Case Study 1 - Bellabeat Wellness Company
The full analysis and relevant files are found on [Github](https://github.com/deep-thinks-tech/data-analytics-case-studies/tree/main/001.fitness-app-case-study). The R files are also available on [Kaggle](https://www.kaggle.com/code/deepajc/fitness-tracker-case-study-in-r).

## Objective - Help Bellabeat Improve Their Marketing Strategy

The analysis follows the **6 steps of the Data Analysis process** - Ask, Prepare, Process, Analyze, Share and Act.

### 1-Ask - Defining the question
In this phase, we define the problem/hypothesis, determine what metrics to use, and define the success factors.

#### 1.0-Background

Bellabeat is a manufacturer of health focused smart products for women since 2013. Empowering women with knowledge about their own health and habits, Bellabeat has grown rapidly and quickly positioned itself as a tech driven wellness company for females.
The co-founder and Chief Creative Officer, Urška Sršen is confident that an analysis of non-Bellabeat consumer data (ie. FitBit fitness tracker usage data) would reveal more opportunities for growth.

#### 1.1-Business Task

Analyze FitBit fitness tracker data to gain insights into how consumers are using the FitBit app and discover trends for Bellabeat marketing strategy.

#### 1.2-Questions to Find Answers to

1. Problem to solve - What should be the marketing strategy of Bellabeat to attract more customers to use its fitness app effectively?

2. Metrics to use - Correlation between number of mins logged on the app and calories burned, number of mins logged and day logged, distance covered and day
Descriptive analysis - What are the trends identified?

3. Success criteria - A prescriptive analysis. How could these trends be used to influence Bellabeat marketing strategy?

#### 1.3-Deliverables
1. A clear summary of the business task
2. A description of all data sources used
3. Documentation of any cleaning or manipulation of data
4. A summary of analysis
5. Supporting visualizations and key findings
6. High-level content recommendations based on the analysis
7. A slide deck -
   + Slide 1 - Executive Summary
   + Finding or Big Reveal
   + Key Metrics excavated from data
   + Recommendations
   + Subsequent slides explain the three points mentioned above in detail
   + Also share spreadsheet and SQL queries relevant to the analysis

#### 1.4-Key Stakeholders
* Urška Sršen: Bellabeat’s co founder and Chief Creative Officer
* Sando Mur: Mathematician, Bellabeat’s co founder and key member of the Bellabeat executive team
* Bellabeat marketing analytics team: A team of data analysts guiding Bellabeat’s marketing strategy.

---


### 2-Prepare - Collecting the data
* Data Location - Publicly available [Kaggle data set](https://www.kaggle.com/datasets/arashnic/fitbit) containing 18 csv files
* Data Behavior
  + Third party data - generated by respondents to a distributed survey via Amazon Mechanical Turk 
  + Data Timestamp - between 03.12.2016-05.12.2016. 
  + Other influencing factors -
    + Only 30 eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. Not a huge data sample
    + Variation between output represents use of different types of Fitbit trackers and individual tracking behaviors / preferences
  + Data Organization - by session ID and activity date
  + Data Credibility (ROCCC)
    + Reliable - Low. The data is obtained from third party - a survey  via Amazon Mechanical Turk
    + Original - Low. Third party data
    + Comprehensive - Medium. Has relevant data to assess the product usage
    + Current - Low. Data is 7 years old
    + Cited - Low. Third party data. Integrity or accuracy unconfirmed and difficult to determine
* Licensing, privacy, security, and accessibility
  + License - CC0: Public Domain
  + Privacy - No user PII captured in the source data
* Data and Tool selected
  + Data - dailyActivity_merged
  + Tool - R

---

### 3-Process - Cleaning the data

We are using R programming to prepare and process the data

#### 3.1 Setting up enviroment - Installing  **Tidyverse** and loading **readr**, **dplyr**, **lubridate**, **ggplot2** packages

```{r envsetup}
#Points to note
#Knitr (engine for dynamic report generation in R used to knit this document) uses CRAN mirror (set of ftp and webservers across the globe with identical, up-to-date, versions of code and documentation for R) to download the packages to be installed. 
#When used in interactive sessions such as console of R script, CRAN mirror need not be explicitly mentioned. 
#Knitr does automatically assume the CRAN mirror and hence need to be added as repos. The repos attribute has to be added to every install.packages statement
#To avoid installation of packages everytime this file is compiled, add a if condition

if (!require(tidyverse)) install.packages("tidyverse",repos = "http://cran.us.r-project.org")
if(!require(plotly)) install.packages("plotly", repos = "http://cran.us.r-project.org")
library(readr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(plotly)
```

#### 3.2 Read the csv file

```{r readcsv}
daily_activity <- read.csv("source-data/dailyActivity_merged.csv")
#on Kaggle daily_activity <- read.csv("/kaggle/input/Daily-Activity-Merged/dailyActivity_merged.csv")
```

#### 3.3 Data Cleaning and Manipulation

##### Steps
1. Observe and familarize with the values
2. Check for nulls, duplicates, and missing values
3. Perform sanity check

```{r dataclean}
#Preview first 10 rows (default is 6)
daily_activity %>% 
  head(10)
```


***Finding the missing or null values***

```{r findnull}
sapply(daily_activity, function(x) sum(is.null(x)))
```

***Basic Description of the data frame***

```{r dfdesc}
str(daily_activity)
```

***Counting the unique ID to confirm whether data set has 30 IDs.***
```{r countuniqueIds}
length(unique(daily_activity$Id))
```


**From the above observation, noted that**

* There is no typo, Null or missing values.

* Data frame has 940 observations and 15 variables.

* ActivityDate is wrongly classified as object data type and has to be converted to datetime data type.

* There are 33 unique IDs, instead of 30 unique IDs as expected from 30 fitness tracker users.

**The following data manipulation is performed**

* Convert ActivityDate to datetime dtype.

* Convert format of ActivityDate to yyyy-mm-dd.

* Create new column DayOfTheWeek by separating the date into day of the week for further analysis.

* Create new column TotalMins being the sum of VeryActiveMinutes, FairlyActiveMinutes, LightlyActiveMinutes and SedentaryMinutes.

* Create new column TotalHours by converting new column in #4 to number of hours.

* Rearrange and rename columns.

**Convert ActivityDate from object to datetime dtype and converting format of ActivityDate to yyyy-mm-dd. Then, printing head to confirm whether it has been updated to datatime64 dtype and dates to yyyy-mm-dd.**

```{r converttodatetime}
#Print the original column type of ActivityDate
print("Original Data Frame Data Type")
sapply(daily_activity,class)

#Convert the data type of ActivityDate to datetime
#daily_activity[["ActivityDate"]] <- as.POSIXct(daily_activity[['ActivityDate']],"%Y-%m-%d") --> Got the error Error in `as.POSIXlt.character()`: ! character string is not in a standard unambiguous format. It is because R is unable to determine the current format of the variable. 
  #One way to fix it is to explicitly calling ActivityDate as character and then applying POSIXct function

#Now convert ActivityDate to datetime
daily_activity[["ActivityDate"]] <- as.POSIXct(as.character(daily_activity[["ActivityDate"]]),format = "%m/%d/%Y")

#Print the modified column type of ActivityDate
print("Converted data frame data type")
sapply(daily_activity, class)

str(daily_activity)

daily_activity %>% 
  head(10)
```

**Rename Columns for uniformity**

```{r colrename}
colnames(daily_activity) <- c('id', 'activity_date', 'total_steps', 'total_distance', 'tracker-distance', 'logged_activities_distance', 'very_active_distance', 'moderately_active_distance', 'light_active_distance', 'sedentary_active_distance', 'very_active_minutes', 'fairly_active_minutes', 'lightly_active_minutes', 'sedentary_minutes', 'calories')

print("Data Frame after column name update")
str(daily_activity)
```

**Add new column total mins and total hours**

```{r addtotalmins}
#Add values using + symbol to add values by row. When sum() was used, the function calculated total sum of all rows instead of by row.
daily_activity$total_mins <- daily_activity$very_active_minutes + daily_activity$fairly_active_minutes + daily_activity$lightly_active_minutes + daily_activity$sedentary_minutes
  

print("After adding total mins variable")
daily_activity %>% 
  select(total_mins,very_active_minutes,fairly_active_minutes,lightly_active_minutes,sedentary_minutes) %>% 
    head(5)
```

```{r addtotalhrs}
daily_activity['total_hrs'] <- round(daily_activity$total_mins/60,0)

print("After adding total hours variable")
daily_activity %>% 
  select (total_hrs, total_mins) %>% 
  head(5)
```

**Add new column to capture day of the week corresponding to activity date**

```{r dayofweek}

daily_activity$day_of_week <- weekdays(as.Date(daily_activity$activity_date))

print("Data frame after adding new variable")
daily_activity %>% 
 head(10)
```

---

### 4-Analyze - Analyzing the data
```{r analysis}
daily_activity %>% 
  summary()
```

#### Observations

1. On average, users logged ***7638 steps or 5.475 km*** which is not adequate. Recommendation is that healthy individuals should reasonably aim for the 10,000-step mark. Source: [Medical News Today article](https://www.medicalnewstoday.com/articles/average-steps-per-day#recommended-steps)
2. On average, please spent ***991.2 minutes*** out of logged 1218.8 minutes OR ***17 hours*** out of 20 hours sendentary. So 85% of the total time people logged on the app were sedentary, indicating people using the app have more a sedentary lifestyle than an active one. 
3. Average calories burned is ***2304 calories***. Could not interpret into detail as calories burned depend on several factors such as the age, weight, daily tasks, exercise, hormones and daily calorie intake.

---


### 5-Share - Visualizing & Sharing your results

In this step, we are creating visualizations to communicate our findings based on our analysis.

#### 5.1 Data Visualization

```{r histogram, echo=FALSE}
#Plot a histogram to determine when do the users log in the fitness app the most
ggplot(daily_activity, aes(x=day_of_week)) + geom_histogram(stat="count",fill="blue") + labs(title = "User Log in App Per Week", x="Day of the Week", y="Frequency")
```

***Frequency of usage across the week***

* In this histogram, we are looking at the frequency of fitness app usage in terms of days of the week.

* Discovered that users prefer or remember to track their activity on the app during midweek from Tuesday to Friday.

* Frequency dropped on Friday and continue on weekends and Monday.

```{r scatterplot, echo=FALSE}
# add annotations and visuals
mean_calories = 2304
mean_steps = 7638

ggplot(daily_activity, aes(x=total_steps, y = calories, color = calories)) + geom_point() + labs(title = "Calories burned for every step taken", x="Steps Taken", y="Calories Burneds")+geom_hline(yintercept=mean_calories, color="orange", size=1)+geom_vline(xintercept = mean_steps, color="blue", size = 1) + annotate("text",x = 30000, y = 1000, label = "Mean Calories",color = "orange", fontface = "bold") + annotate("text",x = 29500, y = 700, label = "Mean Steps", color = "blue", fontface = "bold")
```

***Calories burned for every step taken***

From the scatter plot, we discovered that:

* It is a positive correlation.

* We observed that intensity of calories burned increase when users are at the range of > 0 to 15,000 steps with calories burn rate cooling down from 15,000 steps onwards.

* Noted a few outliers:
  + Zero steps with zero to minimal calories burned.
  + 1 observation of > 35,000 steps with < 3,000 calories burned.
  + Deduced that outliers could be due to natural variation of data, change in user's usage or errors in data collection (ie. miscalculations, data contamination or human error).

```{r scatterplot1, echo=FALSE}
mean_calories = 2304
mean_hours = 20
mean_sedentary = round(991.2 / 60,0)
ggplot(daily_activity, aes(x = total_hrs, y = calories, alpha = 0.8, color = calories)) + geom_point() + labs(title = "Calories burned for Every hour logged", x = "Hours", y = "Calories") + geom_hline(yintercept = mean_calories, color = "orange", size = 1) + geom_vline(xintercept = mean_hours, color = "blue", size = 1) + geom_vline(xintercept = mean_sedentary, color = "green", size = 1) + annotate("text",x = 2.5, y = 5000, label = "Mean Calories",color = "orange", fontface = "bold") + annotate("text",x = 2, y = 4700, label = "Mean Hours", color = "blue", fontface = "bold") + annotate("text",x = 4, y = 4400, label = "Mean Sedentary Hours", color = "green", fontface = "bold")
```

***Calories burned for every hour logged***

The scatter plot is showing:

* A weak positive correlation whereby the increase of hours logged does not translate to more calories being burned. That is largely due to the average sedentary hours (purple line) plotted at the 16 to 17 hours range.
* Again, we can see a few outliers:
  + The same zero value outliers
  + An unusual red dot at the 24 hours with zero calorie burned which may be due to the same reasons as above.
  
```{r piechart, echo=FALSE}
#To plot how each individual activity minutes make up to the overall mins users spend on the app, we use pie chart
#Add up individual minutes
da_very_active_mins = sum(daily_activity$very_active_minutes)
da_fairly_active_mins = sum(daily_activity$fairly_active_minutes)
da_lightly_active_mins = sum(daily_activity$lightly_active_minutes)
da_sedentary_mins = sum(daily_activity$sedentary_minutes)

#Create a new data frame with the activity minutes to be used as data for the pie chart
slices <- c(da_very_active_mins, da_fairly_active_mins, da_lightly_active_mins, da_sedentary_mins)
legends <- c("Very Active Minutes", "Fairly Active Minutes", "Lightly Active Minutes", "Sedentary Minutes")
color <- c("green","blue", "orange","red")
labels <- round(slices*100/sum(slices),1)
labels <- paste(labels, "%", sep="")
#explode <- c(0,0,0,0.1) --> 2d graph did not explode
#plot_ly(df_mins, labels = ~df_labels, values = ~df_mins, type = "pie", color = df_mins) --> does not work
#cex - makes font size relatively smaller
pie(slices, labels = labels, main = "Percentage of Activity in Minutes", border="black", col = color, cex = 0.8)
legend(x = 0.95, y = 0.7, legends, cex=0.7, fill=color)
```

***Percentage of Activity in Minutes***

As seen from the pie chart,

* Sedentary minutes takes the biggest slice at 81.3%.

* This indicates that users are using the fitness app to log daily activities such as daily commute, inactive movements or running errands.

* App is rarely being used to track fitness (ie. running) as per the minor percentage of fairly active activity (1.1%) and very active activity (1.7%).

### 6 - Act

In the final step, we will be delivering our insights and providing recommendations based on our analysis.

Here, we revisit our business questions and share with you our high-level business recommendations.

1. What are the trends identified?

  * Majority of users (81.3%) are using the fitness app to track sedentary activities and not using it for tracking their health habits.

  * Users prefer to track their activities during weekdays as compared to weekends.


2. How could these trends help influence Bellabeat marketing strategy?

  * Bellabeat marketing team can educate users on benefits of using the fitness app for tracking their fitness activities such as running and exercising. 
  * They can run promotions or send notifications to encourage users to log more activities on weekends.